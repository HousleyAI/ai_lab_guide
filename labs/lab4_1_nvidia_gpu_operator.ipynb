{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d95470c",
   "metadata": {},
   "source": [
    "# Nvidia GPU Operator Lab\n",
    "This lab explores the Nvidia GPU Operator installation on the OpenShift cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a69f0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Logging into OpenShift #####\n",
    "### Set Student Number ###\n",
    "student_number = \"##\"      # Replace with your student number\n",
    "\n",
    "if student_number == \"##\":\n",
    "    raise ValueError(\"Please set your student number in the 'student_number' variable.\")\n",
    "\n",
    "### Login to OpenShift ###\n",
    "!oc login -u s{student_number} -p\"!@34QWer\" https://api.ocp.ucsx.hl.dns:6443 --insecure-skip-tls-verify\n",
    "!oc project ai-s{student_number}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebbb556",
   "metadata": {},
   "source": [
    "## Look at the Node labels\n",
    "- The feature.node.kubernetes.io/pci-xxxx labels indicate what pci devices are present on the node\n",
    "  - 10de is the PCI vendor ID for Nvidia\n",
    "  - 15b3 is the PCI vendor for Mellanox\n",
    "- The nvidia.com lables are created by the Nvidia GPU Operator and are useful when scheduling GPU workloads to nodes with GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0251d3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Look at PCIE Node labels ###\n",
    "# !oc describe node ocp5 | grep -i feature.node\n",
    "!oc describe node ocp5 | grep -i pci\n",
    "\n",
    "\n",
    "# feature.node.kubernetes.io/pci-10de.present=true\n",
    "# feature.node.kubernetes.io/pci-10de.sriov.capable=true\n",
    "# feature.node.kubernetes.io/pci-15b3.present=true\n",
    "# feature.node.kubernetes.io/pci-15b3.sriov.capable=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f798855e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Look at NVIDIA specific Node labels ###\n",
    "!oc describe node ocp5 | grep -i nvidia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce3101f",
   "metadata": {},
   "source": [
    "## Look at GPUs on each worker node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a4302f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Look at PCIE Devices on the Nodes ###\n",
    "## This command creates a debug pods on each node and runs lspci to list PCI devices, filtering for NVIDIA devices\n",
    "print(\"### Node: ocp4 ###\")\n",
    "!oc debug node/ocp4 -- chroot /host lspci | grep -i nvidia\n",
    "\n",
    "print(\"\\n\\n### Node: ocp5 ###\")\n",
    "!oc debug node/ocp5 -- chroot /host lspci | grep -i nvidia\n",
    "\n",
    "print(\"\\n\\n### Node: ocp6 ###\")\n",
    "!oc debug node/ocp6 -- chroot /host lspci | grep -i nvidia\n",
    "\n",
    "\n",
    "### Simplified Output ###\n",
    "# Node: ocp4\n",
    "# 31:00.0 3D controller: NVIDIA Corporation TU104GL [Tesla T4] (rev a1)\n",
    "#\n",
    "# Node: ocp5\n",
    "# 3d:00.0 3D controller: NVIDIA Corporation AD102GL [L40] (rev a1)\n",
    "#\n",
    "# Node: ocp6\n",
    "# 3d:00.0 3D controller: NVIDIA Corporation AD102GL [L40] (rev a1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc617e11",
   "metadata": {},
   "source": [
    "## Explore Nvidia GPU Operator Pods\n",
    "- In our environment pods in the gpu operator namespace are usually in sets of 3\n",
    "  - One pod is deployed on each worker node that has a GPU\n",
    "\n",
    "### There are 3 key groups of pods ###\n",
    "- nvidia-driver-daemonset-…\n",
    "  -  Installs and manages the NVIDIA kernel driver on each GPU node\n",
    "  \n",
    "- nvidia-container-toolkit-daemonset-…\n",
    "  -  Installs NVIDIA Container Runtime hooks on each node\n",
    "  \n",
    "- nvidia-device-plugin-daemonset-…\n",
    "  -  Exposes GPUs to Kubernetes as resources that can be scheduled to other pods (nvidia.com/gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021cffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Look at all pods in the nvidia-gpu-operator namespace ###\n",
    "!oc get pods -n nvidia-gpu-operator -o wide\n",
    "\n",
    "# NAME                                                  READY   STATUS      RESTARTS   AGE     IP             NODE   NOMINATED NODE   READINESS GATES\n",
    "# gpu-feature-discovery-42brk                           2/2     Running     0          2d22h   10.128.2.99    ocp5   <none>           <none>\n",
    "# gpu-feature-discovery-65pd5                           2/2     Running     0          2d22h   10.129.2.217   ocp4   <none>           <none>\n",
    "# gpu-feature-discovery-6b5fl                           2/2     Running     0          2d22h   10.131.0.97    ocp6   <none>           <none>\n",
    "# gpu-operator-5dc89c5c45-82ncx                         1/1     Running     0          4d12h   10.128.2.44    ocp5   <none>           <none>\n",
    "# nvidia-container-toolkit-daemonset-lqs54              1/1     Running     0          2d22h   10.129.2.215   ocp4   <none>           <none>\n",
    "# nvidia-container-toolkit-daemonset-tmpsb              1/1     Running     0          2d22h   10.128.2.101   ocp5   <none>           <none>\n",
    "# nvidia-container-toolkit-daemonset-xvgrt              1/1     Running     0          2d22h   10.131.0.99    ocp6   <none>           <none>\n",
    "# nvidia-cuda-validator-gb45d                           0/1     Completed   0          2d22h   10.128.2.104   ocp5   <none>           <none>\n",
    "# nvidia-cuda-validator-jjqbq                           0/1     Completed   0          2d22h   10.131.0.100   ocp6   <none>           <none>\n",
    "# nvidia-cuda-validator-w45dk                           0/1     Completed   0          2d22h   10.129.2.220   ocp4   <none>           <none>\n",
    "# nvidia-dcgm-22fjk                                     1/1     Running     0          2d22h   10.128.2.98    ocp5   <none>           <none>\n",
    "# nvidia-dcgm-exporter-6qvgd                            1/1     Running     0          2d22h   10.128.2.100   ocp5   <none>           <none>\n",
    "# nvidia-dcgm-exporter-j97qb                            1/1     Running     0          2d22h   10.131.0.98    ocp6   <none>           <none>\n",
    "# nvidia-dcgm-exporter-mtz67                            1/1     Running     0          2d22h   10.129.2.219   ocp4   <none>           <none>\n",
    "# nvidia-dcgm-gkmpt                                     1/1     Running     0          2d22h   10.129.2.218   ocp4   <none>           <none>\n",
    "# nvidia-dcgm-llcvb                                     1/1     Running     0          2d22h   10.131.0.96    ocp6   <none>           <none>\n",
    "# nvidia-device-plugin-daemonset-8dnbv                  2/2     Running     0          2d22h   10.128.2.102   ocp5   <none>           <none>\n",
    "# nvidia-device-plugin-daemonset-sxxrn                  2/2     Running     0          2d22h   10.129.2.214   ocp4   <none>           <none>\n",
    "# nvidia-device-plugin-daemonset-vk656                  2/2     Running     0          2d22h   10.131.0.95    ocp6   <none>           <none>\n",
    "# nvidia-driver-daemonset-418.94.202510230424-0-dt77s   4/4     Running     0          2d22h   10.129.2.213   ocp4   <none>           <none>\n",
    "# nvidia-driver-daemonset-418.94.202510230424-0-j6jmx   4/4     Running     0          2d22h   10.128.2.97    ocp5   <none>           <none>\n",
    "# nvidia-driver-daemonset-418.94.202510230424-0-kx5q8   4/4     Running     0          2d22h   10.131.0.93    ocp6   <none>           <none>\n",
    "# nvidia-node-status-exporter-66x7t                     1/1     Running     0          4d      10.131.0.73    ocp6   <none>           <none>\n",
    "# nvidia-node-status-exporter-q2rjv                     1/1     Running     0          4d      10.128.2.77    ocp5   <none>           <none>\n",
    "# nvidia-node-status-exporter-xlxtz                     1/1     Running     0          4d      10.129.2.97    ocp4   <none>           <none>\n",
    "# nvidia-operator-validator-4rz5r                       1/1     Running     0          2d22h   10.131.0.94    ocp6   <none>           <none>\n",
    "# nvidia-operator-validator-dpzls                       1/1     Running     0          2d22h   10.129.2.216   ocp4   <none>           <none>\n",
    "# nvidia-operator-validator-pdmhj                       1/1     Running     0          2d22h   10.128.2.103   ocp5   <none>           <none>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421fba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Change the below name to match name of the pod from ocp4 ###\n",
    "nv_driver_pod_name = \"nvidia-driver-daemonset-418.94.202510230424-0-brdb4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90e1bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Look at the logs of the Nvidia Driver pod ###\n",
    "!oc logs -n nvidia-gpu-operator {nv_driver_pod_name}\n",
    "\n",
    "\n",
    "### Summarized Output ###\n",
    "# ...\n",
    "# Uncompressing NVIDIA Accelerated Graphics Driver for Linux-x86_64 580.95.05....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
    "# + cd NVIDIA-Linux-x86_64-580.95.05\n",
    "# + sh /tmp/install.sh nvinstall\n",
    "# ...\n",
    "# ========== NVIDIA Software Installer ==========\n",
    "\n",
    "# Starting installation of NVIDIA driver version 580.95.05 for Linux kernel version 5.14.0-427.96.1.el9_4.x86_64\n",
    "\n",
    "# + echo -e '\\n========== NVIDIA Software Installer ==========\\n'\n",
    "# + echo -e 'Starting installation of NVIDIA driver version 580.95.05 for Linux kernel version 5.14.0-427.96.1.el9_4.x86_64\\n'\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b764efb",
   "metadata": {},
   "source": [
    "## Run nvidia-smi inside the NVIDIA Driver Daemonset Pods ###\n",
    "- These pods are in charge of managing the NVIDIA drivers on the nodes\n",
    "- The NVIDIA Driver Daemonset Pods can see all GPU processes on the node\n",
    "- where as, running nvidia-smi on any pod with GPU access, will only show processes for that pod\n",
    "  - But will still show the VRAM has been used by other pods\n",
    "- If you look at the pod running on node: ocp4, you will some of the processes for the olama/nvidia nim containers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41174ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: The name of the pod might be different\n",
    "!oc exec -n nvidia-gpu-operator -it {nv_driver_pod_name} -- nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee1837b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Look at the Node description to see the GPU capacity ###\n",
    "## The nvidia.com/gpu capacity will only appear after the Nvidia driver is successfully installed\n",
    "## The reason it shows 8 GPUs instead of 1 is because we enable time-slicing of GPUs in this lab environment\n",
    "!oc describe node ocp4\n",
    "\n",
    "\n",
    "# Capacity:\n",
    "#   cpu:                152\n",
    "#   ephemeral-storage:  523505924Ki\n",
    "#   hugepages-1Gi:      0\n",
    "#   hugepages-2Mi:      0\n",
    "#   memory:             1056450856Ki\n",
    "#   nvidia.com/gpu:     8\n",
    "#   pods:               250"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef433ea",
   "metadata": {},
   "source": [
    "## GPU Time Slicing Configuration\n",
    "- GPU Time Slicing lets multiple containers share a single GPU by loading their data into VRAM, then taking turns executing compute workloads\n",
    "- VRAM usage is not isolated, so one pod can consume all available VRAM, preventing other pods from running AI workloads\n",
    "- Time-slicing settings are managed through a ConfigMap in the nvidia-gpu-operator namespace\n",
    "- For GPUs such as the H100, MIG (Multi-Instance GPU) is often a better option because each MIG instance receives its own dedicated VRAM and guaranteed GPU compute partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9cec69",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loot at list of config maps in the nvidia-gpu-operator namespace ###\n",
    "!oc get configmap -n nvidia-gpu-operator\n",
    "\n",
    "# NAME                            DATA   AGE\n",
    "# device-plugin-gpu-timeslicing   2      6d23h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb230246",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Look at the timeslicing configmap details ###\n",
    "## This shows that the T4 and L40 GPUs are being timesliced into 8 replicas each\n",
    "## Which matches the nvidia.com/gpu capacity above\n",
    "!oc describe configmap device-plugin-gpu-timeslicing -n nvidia-gpu-operator\n",
    "\n",
    "\n",
    "# Name:         device-plugin-gpu-timeslicing\n",
    "# Namespace:    nvidia-gpu-operator\n",
    "# Labels:       <none>\n",
    "# Annotations:  <none>\n",
    "\n",
    "# Data\n",
    "# ====\n",
    "# NVIDIA-L40:\n",
    "# ----\n",
    "# version: v1\n",
    "# sharing:\n",
    "#   timeSlicing:\n",
    "#     renameByDefault: false\n",
    "#     resources:\n",
    "#       - name: nvidia.com/gpu\n",
    "#         replicas: 8\n",
    "# Tesla-T4:\n",
    "# ----\n",
    "# version: v1\n",
    "# sharing:\n",
    "#   timeSlicing:\n",
    "#     renameByDefault: false\n",
    "#     resources:\n",
    "#       - name: nvidia.com/gpu\n",
    "#         replicas: 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5959fadd",
   "metadata": {},
   "source": [
    "## GPU usage in pods\n",
    "- To add a GPU into a pod, you specify the resource request in the manifiest similar to:\n",
    "\n",
    "```yaml\n",
    "resources:\n",
    "  limits:\n",
    "    nvidia.com/gpu: 1            # requesting 1 GPU\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
